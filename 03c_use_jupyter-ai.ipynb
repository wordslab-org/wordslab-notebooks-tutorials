{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d2a2d9-37f3-40d5-9047-2760a94625c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:58:57.633064Z",
     "iopub.status.busy": "2025-08-31T13:58:57.632535Z",
     "iopub.status.idle": "2025-08-31T13:58:58.684873Z",
     "shell.execute_reply": "2025-08-31T13:58:58.684246Z",
     "shell.execute_reply.started": "2025-08-31T13:58:57.633038Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics\n",
    "import os\n",
    "os.environ[\"OLLAMA_HOST\"] = \"http://127.0.0.1:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52f4cc-17ec-409f-b2be-8edae9908a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:58:58.686226Z",
     "iopub.status.busy": "2025-08-31T13:58:58.685858Z",
     "iopub.status.idle": "2025-08-31T13:58:58.691444Z",
     "shell.execute_reply": "2025-08-31T13:58:58.690848Z",
     "shell.execute_reply.started": "2025-08-31T13:58:58.686210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma3:4b', 'qwen3:4b')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = os.getenv(\"OLLAMA_CHAT_MODEL\")\n",
    "code_model = os.getenv(\"OLLAMA_CODE_MODEL\")\n",
    "chat_model,code_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18af1c5-f952-446a-aa8b-b58dfcfdba1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:58:58.692508Z",
     "iopub.status.busy": "2025-08-31T13:58:58.691971Z",
     "iopub.status.idle": "2025-08-31T13:58:58.724781Z",
     "shell.execute_reply": "2025-08-31T13:58:58.723711Z",
     "shell.execute_reply.started": "2025-08-31T13:58:58.692493Z"
    }
   },
   "outputs": [],
   "source": [
    "%config AiMagics.default_language_model = \"ollama:{chat_model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0a7656-5576-4637-b08b-eeb4b2003273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:58:58.730036Z",
     "iopub.status.busy": "2025-08-31T13:58:58.729793Z",
     "iopub.status.idle": "2025-08-31T13:58:58.746173Z",
     "shell.execute_reply": "2025-08-31T13:58:58.745058Z",
     "shell.execute_reply.started": "2025-08-31T13:58:58.730019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Registered new alias `chat`"
      ],
      "text/plain": [
       "Registered new alias `chat`"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai register chat ollama:{chat_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edf1166-bf1b-42dc-ba22-a129a48163fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:58:59.349497Z",
     "iopub.status.busy": "2025-08-31T13:58:59.349277Z",
     "iopub.status.idle": "2025-08-31T13:58:59.354118Z",
     "shell.execute_reply": "2025-08-31T13:58:59.353543Z",
     "shell.execute_reply.started": "2025-08-31T13:58:59.349482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Registered new alias `code`"
      ],
      "text/plain": [
       "Registered new alias `code`"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai register code ollama:{code_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd672e1-7da4-40c5-b33a-e07a5196e5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:59:00.644780Z",
     "iopub.status.busy": "2025-08-31T13:59:00.644559Z",
     "iopub.status.idle": "2025-08-31T13:59:29.160836Z",
     "shell.execute_reply": "2025-08-31T13:59:29.160309Z",
     "shell.execute_reply.started": "2025-08-31T13:59:00.644767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## JupyterAI: A Conversational Interface for Jupyter Notebooks\n",
       "\n",
       "JupyterAI is a Python package that adds a conversational AI interface directly within your Jupyter Notebooks. It leverages large language models (LLMs) like OpenAI's GPT models to allow you to interact with your code, data, and documentation through natural language prompts. \n",
       "\n",
       "Here's a breakdown of what JupyterAI offers:\n",
       "\n",
       "**Core Functionality:**\n",
       "\n",
       "*   **Natural Language Interaction:** You can ask questions, generate code snippets, explain code, and even execute code directly within a notebook cell, all using plain English.\n",
       "*   **Code Generation:**  Request JupyterAI to generate code in various programming languages (Python, JavaScript, etc.) based on your description.\n",
       "*   **Code Explanation:**  Paste a code block into a cell and ask JupyterAI to explain what it does.\n",
       "*   **Documentation Retrieval:**  Ask JupyterAI to fetch documentation for libraries or functions.\n",
       "*   **Interactive Debugging (Limited):** While not a full debugger, it can help you understand error messages and suggest potential fixes.\n",
       "*   **Data Exploration:**  JupyterAI can help you formulate queries for data exploration, potentially integrating with Pandas DataFrames (though this functionality is still evolving).\n",
       "\n",
       "\n",
       "**Key Components & Workflow:**\n",
       "\n",
       "1.  **JupyterAI Kernel:** A specialized kernel that integrates with the LLM and handles the communication between your notebook and the AI model.\n",
       "2.  **LLM Connection:**  The kernel uses an API connection to the LLM (typically OpenAI's GPT models). This requires an OpenAI API key.\n",
       "3.  **Notebook Cells:**  You interact with JupyterAI primarily through magic commands (starting with `%ai`) within Jupyter Notebook cells.\n",
       "4.  **Prompt Engineering:** The quality of your prompts significantly affects the output. Clear, detailed prompts generally lead to better results.\n",
       "\n",
       "**Installation:**\n",
       "\n",
       "```bash\n",
       "pip install jupyterai\n",
       "```\n",
       "\n",
       "**Example Usage (within a Jupyter Notebook):**\n",
       "\n",
       "```python\n",
       "%ai help\n",
       "```\n",
       "\n",
       "This will attempt to retrieve help documentation from the AI model.  You can then follow up with more specific prompts.\n",
       "\n",
       "\n",
       "**Limitations:**\n",
       "\n",
       "*   **Cost:**  Using the OpenAI API incurs costs based on token usage.\n",
       "*   **Accuracy:**  LLMs can sometimes generate incorrect or misleading information. Always verify the output.\n",
       "*   **Context Limitations:**  The AI has limited understanding of the entire notebook context.\n",
       "*   **Development Stage:** JupyterAI is still under active development, and features and performance are subject to change.\n",
       "\n",
       "**Resources:**\n",
       "\n",
       "*   **Official JupyterAI Repository:** [https://github.com/jupyter/jupyterai](https://github.com/jupyter/jupyterai)\n",
       "*   **JupyterAI Documentation:** [https://jupyter.github.io/jupyterai/](https://jupyter.github.io/jupyterai/)\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "Do you want me to elaborate on a specific aspect of JupyterAI, such as:\n",
       "\n",
       "*   Setting up an OpenAI API key?\n",
       "*   Advanced prompt engineering techniques?\n",
       "*   Comparing JupyterAI with other AI-powered notebook tools?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gemma3:4b",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chat\n",
    "What is jupyter-ai ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5cc91-53f3-449c-88c9-eb0ea8725864",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai code -f code\n",
    "Generate a program to compute pi with low precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf405c5-ff59-4faa-87fa-e0d365cd3f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-notebooks-tutorials",
   "language": "python",
   "name": "wordslab-notebooks-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
