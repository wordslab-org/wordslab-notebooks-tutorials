{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9edd711-be05-4568-b31d-25f231766ece",
   "metadata": {},
   "source": [
    "# Jupyter AI\n",
    "\n",
    "https://jupyter-ai.readthedocs.io/en/latest/users/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8303a-b620-471b-b9b5-dd1035341226",
   "metadata": {},
   "source": [
    "## What is Jupyter AI ?\n",
    "\n",
    "Jupyter AI is an innovative tool under incubation as part of the JupyterLab organization. \n",
    "\n",
    "It integrates generative AI with Jupyter notebooks, providing a user-friendly and powerful way to explore generative AI models. \n",
    "\n",
    "The main features of Jupyter AI include:\n",
    "\n",
    "1. **%%ai Magic Command**: This feature turns the Jupyter notebook into a reproducible generative AI playground. It works across various platforms where the IPython kernel runs, including JupyterLab, Jupyter Notebook, Google Colab, Kaggle, and VSCode.\n",
    "\n",
    "2. **Native Chat UI in JupyterLab**: Jupyter AI offers a native chat user interface within JupyterLab, allowing users to interact with generative AI as a conversational assistant.\n",
    "\n",
    "3. **Support for Multiple Generative Model Providers**: Jupyter AI supports a wide range of generative model providers, including AI21, Anthropic, AWS, Cohere, Gemini, Hugging Face, MistralAI, NVIDIA, and OpenAI.\n",
    "\n",
    "4. **Local Model Support**: It provides support for local models through GPT4All and Ollama, enabling the use of generative AI models on consumer-grade machines with ease and privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10324d28-fe9d-45dd-8fa4-e985bdd51c85",
   "metadata": {},
   "source": [
    "## How to configure Jupyter AI for the first use ?\n",
    "\n",
    "To verify that Jupyter AI is properly installed in JupyterLab, follow these steps:\n",
    "\n",
    "### Check if the Jupyter AI Extension is installed\n",
    "\n",
    "Once JupyterLab is open, look for a new tool icon labeled \"Jupyter AI Chat\" in the left-hand sidebar.\n",
    "\n",
    "If you see this icon, it indicates that the Jupyter AI extension has been successfully installed and integrated into JupyterLab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04091679-7d44-48b7-b226-13bd4e096310",
   "metadata": {},
   "source": [
    "### Configure ollama\n",
    "\n",
    "Use the following command line flags to make sure the models:\n",
    "\n",
    "- are not unloaded from memory after 5 min\n",
    "\n",
    "```bash\n",
    "export OLLAMA_KEEP_ALIVE = -1\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "- use more than the default context length of 2048 tokens\n",
    "\n",
    "```bash\n",
    "vi Modefile\n",
    "```\n",
    "\n",
    "```\n",
    "FROM mistral-small\n",
    "PARAMETER num_ctx 32768\n",
    "```\n",
    "\n",
    "```bash\n",
    "ollama create -f Modelfile mistral-small:32k\n",
    "ollama show mistral-small:32k\n",
    "````\n",
    "\n",
    "**Download the language and embedding models on your computer**\n",
    "\n",
    "Open a Terminal and execute the following commands:\n",
    "\n",
    "> ollama pull mistral-small\n",
    "\n",
    "> ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625439f-3d20-41c1-8365-0bf865a77edf",
   "metadata": {},
   "source": [
    "### Configure connections to language models\n",
    "\n",
    "You need to configure a language model and an embedding model in Jupyter AI:\n",
    "\n",
    "**Language Model Configuration**\n",
    "\n",
    "- A language model responds to users' messages in the chat panel by accepting a prompt and producing a response.\n",
    "- Language models are typically pre-trained and ready to use, but it's important to be aware of their biases and incomplete training sets.\n",
    "\n",
    "**Embedding Model Configuration**:\n",
    "\n",
    "- An embedding model is used for learning and asking about local data. These models can transform your data, including documents and source code files, into vectors that help Jupyter AI compose prompts to language models.\n",
    "- Your language model and your embedding model do not need to be provided by the same vendor, but you will need authentication credentials for each model provider that you use.\n",
    "\n",
    "For both models, ensure you have the necessary authentication credentials from the respective providers. This setup allows Jupyter AI to effectively utilize both types of models for various tasks.\n",
    "\n",
    "To select and configure models in Jupyter AI, follow the following steps.\n",
    "\n",
    "**Step 1 - Configure the models**\n",
    "\n",
    "Open the Chat Interface\n",
    "\n",
    "- Once you have started JupyterLab, click the new \"chat\" icon in the left side panel to open the chat interface. \n",
    "\n",
    "Select Models\n",
    "\n",
    "- The first time you open the chat interface, Jupyter AI will prompt you to select which models you want to use as a language model and as an embedding model.\n",
    "- Users may select a language model and, optionally, an embedding model. You should select one of each so that you can use the full functionality of the chat interface.\n",
    "- After making your selections, the UI may display text boxes for one or more settings keys.\n",
    "\n",
    "In the **Completion model** dropdown list, select:\n",
    "\n",
    "```\n",
    "Ollama::*\n",
    "```\n",
    "\n",
    "In the local model ID text input field, type:\n",
    "\n",
    "```\n",
    "mistral-small\n",
    "```\n",
    "\n",
    "In the **Embedding model** dropdown list, select:\n",
    "\n",
    "```\n",
    "Ollama::nomic-embed-text\n",
    "```\n",
    "\n",
    "Click on the gear icon on the right of the title Inline completions model:\n",
    "\n",
    "- Click on the second checkbox: Enabled - Whether to fetch completions **JupyterAI provider**.\n",
    "\n",
    "After you enabled the JupyterAI provider: the dropdown list below **Inline completions model** is activated.\n",
    "\n",
    "Select:\n",
    "\n",
    "```\n",
    "Ollama::*\n",
    "```\n",
    "\n",
    "In the local model ID text input field just below, type:\n",
    "\n",
    "```\n",
    "mistral-small\n",
    "```\n",
    "\n",
    "When everything is ready:\n",
    "\n",
    "- Click on Save Changes button at the bottom.\n",
    "- Then Click on the left pointing arrow at the top.\n",
    "\n",
    "**Step 2 - Test chat**\n",
    "\n",
    "Enter \"hello\" in the Ask Jupyternaut textbox then press Enter.\n",
    "\n",
    "Make sure you get a reponse from the AI assistant (it could take a few seconds to load it in memory).\n",
    "\n",
    "After typing a prompt, be aware that you can click on the little arrow oriented towards the bottom at the right of the input text box to **include the currently selected cells in the context** of the question .\n",
    "\n",
    "You can also **include a complete file** from the workspace (the **base path is /home/workspace**):\n",
    "\n",
    "```\n",
    "summarize @file:wordslab-notebooks-tutorials/06_learn_jupyter_ai.ipynb\n",
    "```\n",
    "\n",
    "**Step 3 - Test embeddings**\n",
    "\n",
    "Type \"/learn /home/workspace/wordslab-notebooks-tutorials/06_learn_jupyter_ai.ipynb\" in the Ask Jupyternaut textbox then press Enter.\n",
    "\n",
    "Make sure the response looks like :\n",
    "\n",
    "```\n",
    "ðŸŽ‰ I have learned documents at /home/workspace/wordslab-notebooks-tutorials/01_explore_hardware.ipynb and I am ready to answer questions about them. You can ask questions about these docs by prefixing your message with /ask.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dc9e4-8d12-44e2-96db-113b81409d7b",
   "metadata": {},
   "source": [
    "### Load the IPython extension in your notebook\n",
    "\n",
    "Before you can use the `%%ai` magic command in your Jupyter notebook, you need to load the IPython extension by running the following code in a notebook cell or IPython shell:\n",
    "\n",
    "```\n",
    "%load_ext jupyter_ai_magics\n",
    "```\n",
    "\n",
    "This command loads the necessary extension that enables the use of AI magics, including `%%ai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31afc087-fdfd-4771-bc7d-7fd58aa0f6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:25.018692Z",
     "iopub.status.busy": "2025-02-01T13:24:25.018274Z",
     "iopub.status.idle": "2025-02-01T13:24:25.588502Z",
     "shell.execute_reply": "2025-02-01T13:24:25.588068Z",
     "shell.execute_reply.started": "2025-02-01T13:24:25.018662Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482dcb9-a36c-4c2c-996c-5007414e768c",
   "metadata": {},
   "source": [
    "### Try to use the `%%ai` Magic Command\n",
    "\n",
    "Once the extension is loaded, you can run %%ai cell magic commands and %ai line magic commands. \n",
    "\n",
    "For example, you can get help with syntax by running %%ai help or %ai help. You can also pass --help as an argument to any line magic command (e.g., %ai list --help) to learn about what the command does and how to use it\n",
    "\n",
    "In a code cell within the notebook, type:\n",
    " ```python\n",
    " %ai help\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836f8d06-a87f-47d3-afdb-4732610406b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:27.141894Z",
     "iopub.status.busy": "2025-02-01T13:24:27.141142Z",
     "iopub.status.idle": "2025-02-01T13:24:27.152329Z",
     "shell.execute_reply": "2025-02-01T13:24:27.151862Z",
     "shell.execute_reply.started": "2025-02-01T13:24:27.141843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] [MODEL_ID]\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  reset     Clear the conversation transcript.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "  version   Prints Jupyter-AI version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbf0db-9f00-4914-99d3-40306b4cf695",
   "metadata": {},
   "source": [
    "If the `%ai` magic command is recognized and you can run AI-related commands without errors, it confirms that Jupyter AI is properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4469a30f-ba0c-42cd-99f6-f569e8cf4597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:29.749883Z",
     "iopub.status.busy": "2025-02-01T13:24:29.748513Z",
     "iopub.status.idle": "2025-02-01T13:24:30.191203Z",
     "shell.execute_reply": "2025-02-01T13:24:30.190832Z",
     "shell.execute_reply.started": "2025-02-01T13:24:29.749839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:mistral-small\n",
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e7c81-2da9-44c7-8f5e-6f231c4d4f0f",
   "metadata": {},
   "source": [
    "You can define a default language model for the `%%ai` magic in Jupyter AI. To do this, you can configure the default model using the IPython `%config` magic.\n",
    "\n",
    "Here are the steps to set a default language model:\n",
    "\n",
    "```python\n",
    "%config AiMagics.default_language_model = \"ollama:mistral-small\"\n",
    "```\n",
    "\n",
    "After running this command, you can invoke the `%%ai` magic without specifying the model each time.\n",
    "\n",
    "By following these steps, you can ensure that your default language model is set for the `%%ai` magic, making it easier to use without repeatedly specifying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1425b0d8-278a-4d25-ac2a-78d164f52baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:32.651316Z",
     "iopub.status.busy": "2025-02-01T13:24:32.649498Z",
     "iopub.status.idle": "2025-02-01T13:24:32.657717Z",
     "shell.execute_reply": "2025-02-01T13:24:32.657055Z",
     "shell.execute_reply.started": "2025-02-01T13:24:32.651274Z"
    }
   },
   "outputs": [],
   "source": [
    "%config AiMagics.default_language_model = \"ollama:mistral-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a036160-ba1d-45f4-bb5b-8a06f157eae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:34.182621Z",
     "iopub.status.busy": "2025-02-01T13:24:34.182473Z",
     "iopub.status.idle": "2025-02-01T13:24:34.706717Z",
     "shell.execute_reply": "2025-02-01T13:24:34.706335Z",
     "shell.execute_reply.started": "2025-02-01T13:24:34.182611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hello!\n",
       "\n",
       "How can I assist you today?\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai\n",
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6462a-c0a7-4670-ac0f-b5eafd7d38b1",
   "metadata": {},
   "source": [
    " You can select the format used to render the output with the flag :\n",
    "\n",
    " ```\n",
    " -f code | html | image | json | markdown | math | md | text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31fed14-29c1-4023-a545-8e344334ca5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:39.197148Z",
     "iopub.status.busy": "2025-02-01T13:24:39.196687Z",
     "iopub.status.idle": "2025-02-01T13:24:41.400771Z",
     "shell.execute_reply": "2025-02-01T13:24:41.400310Z",
     "shell.execute_reply.started": "2025-02-01T13:24:39.197117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Format</th>\n",
       "    <th>Description</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Markdown</td>\n",
       "    <td>A lightweight markup language with plain text formatting syntax.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>HTML</td>\n",
       "    <td>The standard markup language for documents designed to be displayed in a web browser.</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai -f html\n",
    "display the formats in a table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f0158-73f1-450d-8c1c-8a9f784cfcc9",
   "metadata": {},
   "source": [
    "By default, two previous Human/AI message exchanges are included in the context of the new prompt. \n",
    "\n",
    "You can change this using the IPython %config magic, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d825f3e-1284-4382-8363-b9ccef06ccea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:24:45.262862Z",
     "iopub.status.busy": "2025-02-01T13:24:45.261978Z",
     "iopub.status.idle": "2025-02-01T13:24:45.268988Z",
     "shell.execute_reply": "2025-02-01T13:24:45.268616Z",
     "shell.execute_reply.started": "2025-02-01T13:24:45.262823Z"
    }
   },
   "outputs": [],
   "source": [
    "%config AiMagics.max_history = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8a170c-53c8-410b-b77c-359a974a3754",
   "metadata": {},
   "source": [
    "You can reference Python variables in prompt, including In, Out or Error code cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909ddef0-9d00-4808-855c-ad42b7ef6e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T13:25:11.651777Z",
     "iopub.status.busy": "2025-02-01T13:25:11.651540Z",
     "iopub.status.idle": "2025-02-01T13:25:19.495871Z",
     "shell.execute_reply": "2025-02-01T13:25:19.495461Z",
     "shell.execute_reply.started": "2025-02-01T13:25:11.651766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Code Element</th>\n",
       "    <th>Explanation</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td><code>get_ipython()</code></td>\n",
       "    <td>Retrieves the current IPython instance.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td><code>.run_line_magic('config', 'AiMagics.max_history = 4')</code></td>\n",
       "    <td>Runs a line magic command to configure the <code>max_history</code> attribute of <code>AiMagics</code> to 4.</td>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "<h2>Detailed Explanation:</h2>\n",
       "\n",
       "<ul>\n",
       "  <li><strong>IPython:</strong> An interactive computing environment that extends Python's capabilities with features like named inputs and outputs, access to shell commands, and more.</li>\n",
       "  <li><strong>Magic Commands:</strong> Special commands in IPython prefixed with <code>%</code> for line magics and <code>%%</code> for cell magics, providing additional functionality beyond standard Python.</li>\n",
       "  <li><strong>AiMagics:</strong> Likely a custom magic command module or extension related to AI functionalities within the IPython environment.</li>\n",
       "  <li><strong>max_history = 4:</strong> Configures the maximum number of previous commands or states that <code>AiMagics</code> will keep in its history. Setting it to 4 means only the last four commands or states will be retained.</li>\n",
       "</ul>\n",
       "\n",
       "<h2>Example Use Case:</h2>\n",
       "\n",
       "<p>This configuration might be useful in scenarios where you want to limit the amount of historical data stored by AI Magics, potentially to save memory or for performance reasons.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai -f html\n",
    "Please explain the code below:\n",
    "--\n",
    "{In[7]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-notebooks-tutorials",
   "language": "python",
   "name": "wordslab-notebooks-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
