{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9edd711-be05-4568-b31d-25f231766ece",
   "metadata": {},
   "source": [
    "# Jupyter AI\n",
    "\n",
    "https://jupyter-ai.readthedocs.io/en/latest/users/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8303a-b620-471b-b9b5-dd1035341226",
   "metadata": {},
   "source": [
    "## What is Jupyter AI ?\n",
    "\n",
    "Jupyter AI is an innovative tool under incubation as part of the JupyterLab organization. \n",
    "\n",
    "It integrates generative AI with Jupyter notebooks, providing a user-friendly and powerful way to explore generative AI models. \n",
    "\n",
    "The main features of Jupyter AI include:\n",
    "\n",
    "1. **%%ai Magic Command**: This feature turns the Jupyter notebook into a reproducible generative AI playground. It works across various platforms where the IPython kernel runs, including JupyterLab, Jupyter Notebook, Google Colab, Kaggle, and VSCode.\n",
    "\n",
    "2. **Native Chat UI in JupyterLab**: Jupyter AI offers a native chat user interface within JupyterLab, allowing users to interact with generative AI as a conversational assistant.\n",
    "\n",
    "3. **Support for Multiple Generative Model Providers**: Jupyter AI supports a wide range of generative model providers, including AI21, Anthropic, AWS, Cohere, Gemini, Hugging Face, MistralAI, NVIDIA, and OpenAI.\n",
    "\n",
    "4. **Local Model Support**: It provides support for local models through GPT4All and Ollama, enabling the use of generative AI models on consumer-grade machines with ease and privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10324d28-fe9d-45dd-8fa4-e985bdd51c85",
   "metadata": {},
   "source": [
    "## How to configure Jupyter AI for the first use ?\n",
    "\n",
    "To verify that Jupyter AI is properly installed in JupyterLab, follow these steps:\n",
    "\n",
    "### Check for the Jupyter AI Extension\n",
    "\n",
    "Once JupyterLab is open, look for a new tool icon labeled \"Jupyter AI Chat\" in the left-hand sidebar.\n",
    "\n",
    "If you see this icon, it indicates that the Jupyter AI extension has been successfully installed and integrated into JupyterLab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625439f-3d20-41c1-8365-0bf865a77edf",
   "metadata": {},
   "source": [
    "### Configure connections to language models\n",
    "\n",
    "You need to configure a language model and an embedding model in Jupyter AI:\n",
    "\n",
    "**Language Model Configuration**\n",
    "\n",
    "- A language model responds to users' messages in the chat panel by accepting a prompt and producing a response.\n",
    "- Language models are typically pre-trained and ready to use, but it's important to be aware of their biases and incomplete training sets.\n",
    "\n",
    "**Embedding Model Configuration**:\n",
    "\n",
    "- An embedding model is used for learning and asking about local data. These models can transform your data, including documents and source code files, into vectors that help Jupyter AI compose prompts to language models.\n",
    "- Your language model and your embedding model do not need to be provided by the same vendor, but you will need authentication credentials for each model provider that you use.\n",
    "\n",
    "For both models, ensure you have the necessary authentication credentials from the respective providers. This setup allows Jupyter AI to effectively utilize both types of models for various tasks.\n",
    "\n",
    "To select and configure models in Jupyter AI, follow the following steps.\n",
    "\n",
    "**Step 1 - Download the language and embedding models on your computer**\n",
    "\n",
    "Open a Terminal and execute the following commands:\n",
    "\n",
    "> ollama pull mistral-small\n",
    "\n",
    "> ollama pull snowflake-arctic-embed\n",
    "\n",
    "**Step 2 - Configure the models**\n",
    "\n",
    "Open the Chat Interface\n",
    "\n",
    "- Once you have started JupyterLab, click the new \"chat\" icon in the left side panel to open the chat interface. \n",
    "\n",
    "Select Models\n",
    "\n",
    "- The first time you open the chat interface, Jupyter AI will prompt you to select which models you want to use as a language model and as an embedding model.\n",
    "- Users may select a language model and, optionally, an embedding model. You should select one of each so that you can use the full functionality of the chat interface.\n",
    "- After making your selections, the UI may display text boxes for one or more settings keys.\n",
    "\n",
    "In the Completion model dropdown list, select:\n",
    "\n",
    "```\n",
    "Ollama::*\n",
    "```\n",
    "\n",
    "In the local model ID text input field, type:\n",
    "\n",
    "```\n",
    "mistral-small\n",
    "```\n",
    "\n",
    "In the Embedding model dropdown list, select:\n",
    "\n",
    "```\n",
    "Ollama::snowflake-arctic-embed\n",
    "```\n",
    "\n",
    "- Click on Save Changes button at the bottom.\n",
    "- Then Click on the left pointing arrow at the top.\n",
    "\n",
    "**Step 3 - Test chat**\n",
    "\n",
    "Enter \"hello\" in the Ask Jupyternaut textbox then press Enter.\n",
    "\n",
    "Make sure you get a reponse from the AI assistant (it could take a few seconds to load it in memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dc9e4-8d12-44e2-96db-113b81409d7b",
   "metadata": {},
   "source": [
    "### Load the IPython extension in your notebook\n",
    "\n",
    "Before you can use the `%%ai` magic command in your Jupyter notebook, you need to load the IPython extension by running the following code in a notebook cell or IPython shell:\n",
    "\n",
    "```\n",
    "%load_ext jupyter_ai_magics\n",
    "```\n",
    "\n",
    "This command loads the necessary extension that enables the use of AI magics, including `%%ai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31afc087-fdfd-4771-bc7d-7fd58aa0f6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:08:19.753831Z",
     "iopub.status.busy": "2025-02-01T00:08:19.753686Z",
     "iopub.status.idle": "2025-02-01T00:08:20.564626Z",
     "shell.execute_reply": "2025-02-01T00:08:20.564299Z",
     "shell.execute_reply.started": "2025-02-01T00:08:19.753821Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482dcb9-a36c-4c2c-996c-5007414e768c",
   "metadata": {},
   "source": [
    "### Try to use the `%%ai` Magic Command\n",
    "\n",
    "Once the extension is loaded, you can run %%ai cell magic commands and %ai line magic commands. \n",
    "\n",
    "For example, you can get help with syntax by running %%ai help or %ai help. You can also pass --help as an argument to any line magic command (e.g., %ai list --help) to learn about what the command does and how to use it\n",
    "\n",
    "In a code cell within the notebook, type:\n",
    " ```python\n",
    " %ai help\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "836f8d06-a87f-47d3-afdb-4732610406b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:12:35.861387Z",
     "iopub.status.busy": "2025-02-01T00:12:35.860966Z",
     "iopub.status.idle": "2025-02-01T00:12:35.871917Z",
     "shell.execute_reply": "2025-02-01T00:12:35.871446Z",
     "shell.execute_reply.started": "2025-02-01T00:12:35.861361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] [MODEL_ID]\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  reset     Clear the conversation transcript.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "  version   Prints Jupyter-AI version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbf0db-9f00-4914-99d3-40306b4cf695",
   "metadata": {},
   "source": [
    "If the `%ai` magic command is recognized and you can run AI-related commands without errors, it confirms that Jupyter AI is properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4469a30f-ba0c-42cd-99f6-f569e8cf4597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:15:49.015872Z",
     "iopub.status.busy": "2025-02-01T00:15:49.015424Z",
     "iopub.status.idle": "2025-02-01T00:16:04.672791Z",
     "shell.execute_reply": "2025-02-01T00:16:04.672207Z",
     "shell.execute_reply.started": "2025-02-01T00:15:49.015842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:mistral-small\n",
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e7c81-2da9-44c7-8f5e-6f231c4d4f0f",
   "metadata": {},
   "source": [
    "You can define a default language model for the `%%ai` magic in Jupyter AI. To do this, you can configure the default model using the IPython `%config` magic.\n",
    "\n",
    "Here are the steps to set a default language model:\n",
    "\n",
    "```python\n",
    "%config AiMagics.default_language_model = \"ollama:mistral-small\"\n",
    "```\n",
    "\n",
    "After running this command, you can invoke the `%%ai` magic without specifying the model each time.\n",
    "\n",
    "By following these steps, you can ensure that your default language model is set for the `%%ai` magic, making it easier to use without repeatedly specifying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1425b0d8-278a-4d25-ac2a-78d164f52baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:22:51.330895Z",
     "iopub.status.busy": "2025-02-01T00:22:51.330469Z",
     "iopub.status.idle": "2025-02-01T00:22:51.338251Z",
     "shell.execute_reply": "2025-02-01T00:22:51.337685Z",
     "shell.execute_reply.started": "2025-02-01T00:22:51.330867Z"
    }
   },
   "outputs": [],
   "source": [
    "%config AiMagics.default_language_model = \"ollama:mistral-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a036160-ba1d-45f4-bb5b-8a06f157eae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:29:18.494100Z",
     "iopub.status.busy": "2025-02-01T00:29:18.493664Z",
     "iopub.status.idle": "2025-02-01T00:29:19.228484Z",
     "shell.execute_reply": "2025-02-01T00:29:19.228132Z",
     "shell.execute_reply.started": "2025-02-01T00:29:18.494070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Hello!\n",
       "\n",
       "How can I assist you today?\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d99bb27-2330-413e-8b8b-0067f3b4b649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:26:02.482749Z",
     "iopub.status.busy": "2025-02-01T00:26:02.482570Z",
     "iopub.status.idle": "2025-02-01T00:26:04.351801Z",
     "shell.execute_reply": "2025-02-01T00:26:04.351458Z",
     "shell.execute_reply.started": "2025-02-01T00:26:02.482738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Greeting</title>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Hello!</h1>\n",
       "    <p>How can I assist you today?</p>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai -f html\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e51ef65-a174-41a6-872a-d3502a22da24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T00:48:29.909141Z",
     "iopub.status.busy": "2025-02-01T00:48:29.908704Z",
     "iopub.status.idle": "2025-02-01T00:48:31.315036Z",
     "shell.execute_reply": "2025-02-01T00:48:31.314646Z",
     "shell.execute_reply.started": "2025-02-01T00:48:29.909125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# What does the previous cell do?\n",
       "\n",
       "The previous cell provides a brief description of this notebook and its purpose.\n",
       "\n",
       "It also asks you to clarify your request if it's not clear, ambiguous or does not have enough context for me to accurately answer.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "mistral-small",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai\n",
    "what does the previous cell do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d884400-d092-4f32-899d-6869672f9723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-01T01:03:14.890802Z",
     "iopub.status.busy": "2025-02-01T01:03:14.889931Z",
     "iopub.status.idle": "2025-02-01T01:03:14.919593Z",
     "shell.execute_reply": "2025-02-01T01:03:14.918701Z",
     "shell.execute_reply.started": "2025-02-01T01:03:14.890762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n"
     ]
    }
   ],
   "source": [
    "# Print the list of prime numbers to 100\n",
    "\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "primes = [num for num in range(2, 101) if is_prime(num)]\n",
    "print(primes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-notebooks-tutorials",
   "language": "python",
   "name": "wordslab-notebooks-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
